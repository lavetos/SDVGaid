"""AI service for OpenAI/Claude integration"""
import os
import json
from typing import Optional, List, Dict, Any
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None
try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None
from prompts import get_conversation_history, get_low_energy_prompt, get_high_energy_prompt
from ai_functions import get_function_schema
import ai_functions as af_module


class AIService:
    """Service for AI interactions"""
    
    def __init__(self):
        self.openai_client = None
        self.claude_client = None
        self.current_provider = None
        
        # Try OpenAI first
        openai_key = os.getenv('OPENAI_API_KEY')
        if openai_key and OpenAI:
            try:
                self.openai_client = OpenAI(api_key=openai_key)
                self.current_provider = 'openai'
            except Exception as e:
                print(f"OpenAI init error: {e}")
        else:
            # Try Claude
            claude_key = os.getenv('ANTHROPIC_API_KEY')
            if claude_key and Anthropic:
                try:
                    self.claude_client = Anthropic(api_key=claude_key)
                    self.current_provider = 'claude'
                except Exception as e:
                    print(f"Claude init error: {e}")
        
        if not self.current_provider:
            raise ValueError(
                "‚ùå AI provider is required!\n"
                "Set OPENAI_API_KEY or ANTHROPIC_API_KEY in .env file.\n"
                "Get keys from: https://platform.openai.com or https://console.anthropic.com"
            )
    
    async def process_message(self, user_message: str, user_id: int, energy_level: Optional[int] = None) -> str:
        """
        Process user message with AI
        
        Args:
            user_message: User's message
            user_id: Telegram user ID
            energy_level: Optional current energy level (40, 60, 80)
        
        Returns:
            AI response
        """
        
        try:
            if self.current_provider == 'openai':
                return await self._process_openai(user_message, user_id, energy_level)
            elif self.current_provider == 'claude':
                return await self._process_claude(user_message, user_id, energy_level)
            else:
                return "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã /goal, /plan, /reminders üíõ"
        except Exception as e:
            import traceback
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"AI error processing message '{user_message[:50]}...': {e}", exc_info=True)
            print(f"AI error: {e}")
            traceback.print_exc()
            # –ë–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            error_msg = str(e)[:150] if str(e) else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
            return f"–£–ø—Å, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ üòÖ\n\nüí° –ü–æ–ø—Ä–æ–±—É–π:\n‚Ä¢ –ù–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ\n‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã: /goal, /plan, /note, /reminders\n‚Ä¢ –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ: '–∑–∞–ø–∏—à–∏ –∫—É–ø–∏—Ç—å –º–æ–ª–æ–∫–æ'\n\nüíõ"
    
    async def _process_openai(self, user_message: str, user_id: int, energy_level: Optional[int]) -> str:
        """Process with OpenAI"""
        import logging
        logger = logging.getLogger(__name__)
        
        try:
            messages = get_conversation_history()
            
            # Add energy level context if available
            if energy_level:
                if energy_level < 40:
                    messages.append({"role": "system", "content": get_low_energy_prompt()})
                elif energy_level > 80:
                    messages.append({"role": "system", "content": get_high_energy_prompt()})
            
            # Add user message
            messages.append({"role": "user", "content": user_message})
            
            # Get function tools
            tools = get_function_schema()
            
            # Call OpenAI
            logger.debug(f"Calling OpenAI with {len(messages)} messages, user_id={user_id}")
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # Cheaper model
                messages=messages,
                tools=tools,
                tool_choice="auto",
                temperature=0.7,
                max_tokens=500
            )
            
            choice = response.choices[0]
            message = choice.message
            
            # Handle function calls
            if message.tool_calls:
                logger.debug(f"OpenAI returned {len(message.tool_calls)} tool calls")
                return await self._handle_tool_calls(message.tool_calls, messages, user_id)
            
            # Return text response
            response_text = message.content or "–ü–æ–Ω—è–ª —Ç–µ–±—è üíõ"
            logger.debug(f"OpenAI text response: {response_text[:50]}...")
            return response_text
        except Exception as e:
            import traceback
            logger.error(f"Error in _process_openai: {e}", exc_info=True)
            traceback.print_exc()
            raise
    
    async def _process_claude(self, user_message: str, user_id: int, energy_level: Optional[int]) -> str:
        """Process with Claude"""
        messages = get_conversation_history()
        
        # Add energy level context if available
        if energy_level:
            if energy_level < 40:
                messages.append({"role": "system", "content": get_low_energy_prompt()})
            elif energy_level > 80:
                messages.append({"role": "system", "content": get_high_energy_prompt()})
        
        # Add user message
        messages.append({"role": "user", "content": user_message})
        
        # Call Claude
        # Note: Claude's tools are slightly different, adapt as needed
        response = self.claude_client.messages.create(
            model="claude-3-haiku-20240307",  # Cheapest Claude model
            max_tokens=500,
            messages=[msg for msg in messages if msg["role"] != "system"],  # System messages handled differently
            system=get_conversation_history()[0]["content"]
        )
        
        return response.content[0].text
    
    async def _handle_tool_calls(self, tool_calls: List[Any], messages: List[Dict], user_id: int) -> str:
        """Handle tool/function calls from AI"""
        import logging
        logger = logging.getLogger(__name__)
        results = []
        
        for tool_call in tool_calls:
            try:
                function_name = tool_call.function.name
                arguments = json.loads(tool_call.function.arguments)
                logger.debug(f"Handling tool call: {function_name} with args: {arguments}")
                
                # Call function handler
                function_handler = af_module.function_handler
                if not function_handler:
                    logger.error("Function handler not initialized!")
                    result = {"success": False, "message": "–§—É–Ω–∫—Ü–∏–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞."}
                else:
                    # –î–ª—è create_reminder –Ω—É–∂–µ–Ω chat_id (telegram user_id)
                    # user_id - —ç—Ç–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π ID –∏–∑ –ë–î, chat_id - —ç—Ç–æ telegram user_id
                    chat_id = user_id  # –í –Ω–∞—à–µ–π —Å—Ö–µ–º–µ –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    result = await function_handler.handle_function_call(function_name, arguments, user_id, chat_id)
                    logger.debug(f"Function {function_name} returned: success={result.get('success')}")
                
                results.append(result)
                
                # Add result back to conversation
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": function_name,
                    "content": json.dumps(result)
                })
            except Exception as e:
                import traceback
                logger.error(f"Error handling tool call {tool_call.function.name if hasattr(tool_call, 'function') else 'unknown'}: {e}", exc_info=True)
                traceback.print_exc()
                results.append({
                    "success": False,
                    "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏: {str(e)[:100]}"
                })
        
        # If we got successful results, format them nicely
        success_messages = [r.get("message", "") for r in results if r.get("success")]
        error_messages = [r.get("message", "") for r in results if not r.get("success")]
        
        if success_messages:
            # If multiple notes/reminders were created, combine messages
            if len(success_messages) == 1:
                return success_messages[0]
            else:
                # Multiple actions completed
                return "\n".join(success_messages)
        elif error_messages:
            # –ï—Å–ª–∏ –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —É–ø–∞–ª–∏ —Å –æ—à–∏–±–∫–æ–π
            return error_messages[0] if len(error_messages) == 1 else f"–û—à–∏–±–∫–∏: {', '.join(error_messages)}"
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ —É—Å–ø–µ—Ö–æ–≤, –Ω–∏ –æ—à–∏–±–æ–∫ (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        return "–í—ã–ø–æ–ª–Ω–µ–Ω–æ, –Ω–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ /notes –∏–ª–∏ /reminders üíõ"
    
    async def breakdown_task(self, task_description: str) -> List[str]:
        """Break down a task into microsteps"""
        prompt = f"–†–∞–∑–±–µ–π —ç—Ç—É –∑–∞–¥–∞—á—É –Ω–∞ 3-5 –ø—Ä–æ—Å—Ç—ã—Ö —à–∞–≥–æ–≤ (–∫–∞–∂–¥—ã–π ‚â§10 –º–∏–Ω—É—Ç):\n\n{task_description}\n\n–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫ —à–∞–≥–æ–≤, –∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏."
        
        try:
            response = await self.process_message(prompt, 0)
            # Parse response into list
            steps = [step.strip() for step in response.split('\n') if step.strip() and not step.strip().startswith('*')]
            return steps[:5]  # Max 5 steps
        except Exception as e:
            print(f"Error breaking down task: {e}")
            return [
                "1) –û—Ç–∫—Ä–æ–π —Ñ–∞–π–ª",
                "2) –°–¥–µ–ª–∞–π –ø–µ—Ä–≤—ã–π —à–∞–≥",
                "3) –ü—Ä–æ–¥–æ–ª–∂–∞–π –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —à–∞–≥–∞–º–∏"
            ]
    
    async def reframe_criticism(self, user_message: str) -> str:
        """Reframe user's self-criticism into support"""
        prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç:\n{user_message}\n\n–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —ç—Ç–æ –≤ –º—è–≥–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É –±–µ–∑ —Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∏. –ö–æ—Ä–æ—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."
        
        try:
            return await self.process_message(prompt, 0)
        except Exception as e:
            print(f"Error reframing: {e}")
            return "–¢—ã –Ω–µ –æ–±—è–∑–∞–Ω –±—ã—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–º üíõ"


# Global AI service instance
ai_service = AIService()

