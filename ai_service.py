"""AI service for OpenAI/Claude integration"""
import os
import json
from typing import Optional, List, Dict, Any
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None
try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None
from prompts import get_conversation_history, get_low_energy_prompt, get_high_energy_prompt
from ai_functions import get_function_schema
import ai_functions as af_module


class AIService:
    """Service for AI interactions"""
    
    def __init__(self):
        self.openai_client = None
        self.claude_client = None
        self.current_provider = None
        
        # Try OpenAI first
        openai_key = os.getenv('OPENAI_API_KEY')
        if openai_key and OpenAI:
            try:
                self.openai_client = OpenAI(api_key=openai_key)
                self.current_provider = 'openai'
            except Exception as e:
                print(f"OpenAI init error: {e}")
        else:
            # Try Claude
            claude_key = os.getenv('ANTHROPIC_API_KEY')
            if claude_key and Anthropic:
                try:
                    self.claude_client = Anthropic(api_key=claude_key)
                    self.current_provider = 'claude'
                except Exception as e:
                    print(f"Claude init error: {e}")
        
        if not self.current_provider:
            raise ValueError(
                "‚ùå AI provider is required!\n"
                "Set OPENAI_API_KEY or ANTHROPIC_API_KEY in .env file.\n"
                "Get keys from: https://platform.openai.com or https://console.anthropic.com"
            )
    
    async def process_message(self, user_message: str, user_id: int, energy_level: Optional[int] = None) -> str:
        """
        Process user message with AI
        
        Args:
            user_message: User's message
            user_id: Telegram user ID
            energy_level: Optional current energy level (40, 60, 80)
        
        Returns:
            AI response
        """
        
        try:
            if self.current_provider == 'openai':
                return await self._process_openai(user_message, user_id, energy_level)
            elif self.current_provider == 'claude':
                return await self._process_claude(user_message, user_id, energy_level)
        except Exception as e:
            print(f"AI error: {e}")
            return "–£–ø—Å, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ üòÖ –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—ã—á–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã!"
    
    async def _process_openai(self, user_message: str, user_id: int, energy_level: Optional[int]) -> str:
        """Process with OpenAI"""
        messages = get_conversation_history()
        
        # Add energy level context if available
        if energy_level:
            if energy_level < 40:
                messages.append({"role": "system", "content": get_low_energy_prompt()})
            elif energy_level > 80:
                messages.append({"role": "system", "content": get_high_energy_prompt()})
        
        # Add user message
        messages.append({"role": "user", "content": user_message})
        
        # Get function tools
        tools = get_function_schema()
        
        # Call OpenAI
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",  # Cheaper model
            messages=messages,
            tools=tools,
            tool_choice="auto",
            temperature=0.7,
            max_tokens=500
        )
        
        choice = response.choices[0]
        message = choice.message
        
        # Handle function calls
        if message.tool_calls:
            return await self._handle_tool_calls(message.tool_calls, messages, user_id)
        
        # Return text response
        return message.content
    
    async def _process_claude(self, user_message: str, user_id: int, energy_level: Optional[int]) -> str:
        """Process with Claude"""
        messages = get_conversation_history()
        
        # Add energy level context if available
        if energy_level:
            if energy_level < 40:
                messages.append({"role": "system", "content": get_low_energy_prompt()})
            elif energy_level > 80:
                messages.append({"role": "system", "content": get_high_energy_prompt()})
        
        # Add user message
        messages.append({"role": "user", "content": user_message})
        
        # Call Claude
        # Note: Claude's tools are slightly different, adapt as needed
        response = self.claude_client.messages.create(
            model="claude-3-haiku-20240307",  # Cheapest Claude model
            max_tokens=500,
            messages=[msg for msg in messages if msg["role"] != "system"],  # System messages handled differently
            system=get_conversation_history()[0]["content"]
        )
        
        return response.content[0].text
    
    async def _handle_tool_calls(self, tool_calls: List[Any], messages: List[Dict], user_id: int) -> str:
        """Handle tool/function calls from AI"""
        results = []
        
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)
            
            # Call function handler
            function_handler = af_module.function_handler
            if not function_handler:
                result = {"error": "Function handler not initialized"}
            else:
                # –î–ª—è create_reminder –Ω—É–∂–µ–Ω chat_id (telegram user_id)
                # user_id - —ç—Ç–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π ID –∏–∑ –ë–î, chat_id - —ç—Ç–æ telegram user_id
                chat_id = user_id  # –í –Ω–∞—à–µ–π —Å—Ö–µ–º–µ –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                result = await function_handler.handle_function_call(function_name, arguments, user_id, chat_id)
            results.append(result)
            
            # Add result back to conversation
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": function_name,
                "content": json.dumps(result)
            })
        
        # If we got a successful result with actions, return user-friendly message
        if len(results) == 1:
            result = results[0]
            if result.get("success"):
                return result.get("message", "–ì–æ—Ç–æ–≤–æ! ‚úÖ")
        
        # Otherwise, get AI to summarize
        messages.append({"role": "user", "content": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ø—Ä–æ—Å–∏–ª..."})
        
        if self.current_provider == 'openai':
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=300
            )
            return response.choices[0].message.content
        
        return "–ì–æ—Ç–æ–≤–æ! ‚úÖ"
    
    async def breakdown_task(self, task_description: str) -> List[str]:
        """Break down a task into microsteps"""
        prompt = f"–†–∞–∑–±–µ–π —ç—Ç—É –∑–∞–¥–∞—á—É –Ω–∞ 3-5 –ø—Ä–æ—Å—Ç—ã—Ö —à–∞–≥–æ–≤ (–∫–∞–∂–¥—ã–π ‚â§10 –º–∏–Ω—É—Ç):\n\n{task_description}\n\n–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫ —à–∞–≥–æ–≤, –∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏."
        
        try:
            response = await self.process_message(prompt, 0)
            # Parse response into list
            steps = [step.strip() for step in response.split('\n') if step.strip() and not step.strip().startswith('*')]
            return steps[:5]  # Max 5 steps
        except Exception as e:
            print(f"Error breaking down task: {e}")
            return [
                "1) –û—Ç–∫—Ä–æ–π —Ñ–∞–π–ª",
                "2) –°–¥–µ–ª–∞–π –ø–µ—Ä–≤—ã–π —à–∞–≥",
                "3) –ü—Ä–æ–¥–æ–ª–∂–∞–π –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —à–∞–≥–∞–º–∏"
            ]
    
    async def reframe_criticism(self, user_message: str) -> str:
        """Reframe user's self-criticism into support"""
        prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç:\n{user_message}\n\n–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —ç—Ç–æ –≤ –º—è–≥–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É –±–µ–∑ —Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∏. –ö–æ—Ä–æ—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."
        
        try:
            return await self.process_message(prompt, 0)
        except Exception as e:
            print(f"Error reframing: {e}")
            return "–¢—ã –Ω–µ –æ–±—è–∑–∞–Ω –±—ã—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–º üíõ"


# Global AI service instance
ai_service = AIService()

